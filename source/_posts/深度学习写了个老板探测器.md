---
title: 深度学习写了个老板探测器
tags: [python,树莓派,人脸识别]
categories: 树莓派
---

如果上班的时候想放松一下，或者直说想偷偷懒，看点和工作无关的网页，这时候万一老板突然出现在背后，会不会感到很难堪呢？

有的浏览器设置了boss按键，手快的人还可以切换屏幕，不过总会显得不自然，而且经常搞的手忙脚乱的。

一个日本程序员决定自己动手，编写一个一劳永逸的办法，我们来看看他是怎么实现的吧

1. 思路很直接：用网络摄像头自动识别在工位通道走过的人脸，如果确认是老板的话，就用一张写满了代码的截图覆盖到整个屏幕上。  
2.   
3. 整个工程中应用了Keras深度学习框架来建立识别人脸的神经网络，和一个网络摄像头用来捕捉老板的人脸。  

任务是这样的

当老板接近我的工位时，电脑就会自动切换屏幕

办公室的情况如下：

从老板的座位到我的座位大约6~7米，他会在离开座位后4到5秒钟到达我的座位，因此，需要在这之前隐藏屏幕，所以时间比较紧迫。

策略



1. 首先需要让电脑完成对老板面部的深度学习。然后在我的办公桌上摆上一个网络摄像头，让摄像头对着通道，当网络摄像头捕捉到老板的脸时就切换屏幕。  

嗯，这是一个完美的项目。先取一个好名字，就叫Boss Sensor（老板探测器）好了。

![img](http://img.blog.csdn.net/20170112101129874)

Boss Sensor的简单结构图如下：

![img](http://img.blog.csdn.net/20170112101203328)

处理过程分为三步：

- 网络摄像头实时拍摄图像
- 学习模型检测和识别所拍摄图像的人脸
- 如果识别结果是老板则切换屏幕

所需要的技术实现只有三项：

- 拍摄人脸图像
- 识别人脸图像
- 切换屏幕

一步步完成之后整合就可以了。

拍摄人脸图像

首先找一个网络摄像头，我用的是BUFFALO BSW20KM11BK摄像头，大家随便找个清晰度够的就可以了。

![img](http://img.blog.csdn.net/20170112101306721)

最好不要用相机自带的识别软件裁剪人脸，因为后面的深度学习过程还需要处理。所以，我用[Python](http://lib.csdn.net/base/python)和[OpenCV](http://lib.csdn.net/base/opencv)编写了一段裁剪人脸图像的脚本，代码在这里下载：

[https://github.com/Hironsan/BossSensor/blob/master/camera_reader.py](https://github.com/Hironsan/BossSensor/blob/master/camera_reader.py)

偷拍到的人脸图像比我之前设想的更清楚

识别人脸图像

接下来，要用[机器学习](http://lib.csdn.net/base/machinelearning)教会电脑识别老板的脸。

我们需要以下三个步骤：

- 采集图像
- 图像预处理
- 建立机器学习模型

让我们一个接一个看一下。

采集图像

首先，需要收集大量的图片供电脑学习。一般来说有三种大量收集图片的方法：

- 谷歌图片搜索
- Facebook的图像采集
- 从视频里截图

**[plain]** [view plain](http://blog.csdn.net/jxw167/article/details/54375336#) [copy](http://blog.csdn.net/jxw167/article/details/54375336#)

1. 一开始，我像电影里的特工一样收集了各种搜索引擎上的老板照片，还有Facebook上老板自己上传的照片，但说实话，没有收集到足够的图像。所以，反正老板就在身边，我就简单粗暴的拍摄了一段他的视频，然后把视频分解成大量的图像。  

图像预处理

现在我有很多人脸图像了，但还不能拿它们来建立学习模型，必须要裁剪掉与脸部不相关的部分。

我使用ImageMagick来提取人脸，你可以用别的图像软件来做。

总之，最后我收集了大量的人脸图像，就像这样:

估计我是全世界拥有最多老板头像的人了，肯定比他爸爸妈妈要多的多。

现在可以准备机器学习了。

建立机器学习模型

Keras框架用来建立卷积神经网络和神经网络培训。Tensorflow用来写Keras的后端。如果只识别脸部的话，可以调用一些Web API比如微软的Computer Vision API，但这次我决定自己来实现，因为这个项目需要确保实时性。

网络体系结构大体如下，Keras非常方便，它可以很轻松的输出这样的结构:

代码在这里下载：

[https://github.com/Hironsan/BossSensor/blob/master/boss_train.py](https://github.com/Hironsan/BossSensor/blob/master/boss_train.py)

至此，只要老板出现在摄像头中，我就可以识别出他来了。

**切换屏幕**

最后一步，很简单，学习模型识别出老板的脸之后，把电脑屏幕换掉就好了。

我是程序员，所以我准备了这样一张图：

电脑上只显示这张图片，这样就可以假装我在认真工作了。

这张图需要全屏显示，所以我调用了PyQt库，代码在这里下载：

[https://github.com/Hironsan/BossSensor/blob/master/image_show.py](https://github.com/Hironsan/BossSensor/blob/master/image_show.py)

一切工作都完成了。

成品

最后把分别实现的技术整合起来并验证，真的成功了！

“现在老板离开了座位，正走向我的工位。”

“opencv已经检测出人脸，将人脸图像发送给学习模型。”

**![img](http://img.blog.csdn.net/20170112102005084)**



“学习模型认出了他，屏幕自动切换。ヽ(‘ ∇‘ )ノ”

![img](http://img.blog.csdn.net/20170112102043683)

这就是我的Boss Sensor，全部的源码都放在github上了，可以在这里下载：

[https://github.com/Hironsan/BossSensor](https://github.com/Hironsan/BossSensor)

总结

结合网络摄像头的实时图像采集和Keras深度学习框架，确实可以完成人脸识别。

在实践过程中，我发现OpenCV的图像精度不够高，虽然不影响识别，但我准备改用Dlib来提高精度，另外我想自己编写人脸检测训练模型。

网络摄像头获取的图像不够清晰，我准备换个摄像头。